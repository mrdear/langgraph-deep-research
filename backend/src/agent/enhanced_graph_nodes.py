"""
å¢å¼ºçš„GraphèŠ‚ç‚¹ - é›†æˆæ™ºèƒ½Firecrawlå†…å®¹å¢å¼ºåŠŸèƒ½
"""

import os
import json
from typing import List, Dict, Any
from datetime import datetime
from langchain_core.runnables import RunnableConfig
from langchain_core.messages import AIMessage

from agent.state import OverallState, ReflectionState
from agent.content_enhancement_decision import (
    get_content_enhancement_decision_maker,
    EnhancementDecision
)
from agent.utils import get_research_topic


def content_enhancement_analysis(state: OverallState, config: RunnableConfig) -> dict:
    """
    æ™ºèƒ½å†…å®¹å¢å¼ºåˆ†æèŠ‚ç‚¹ - å†³å®šæ˜¯å¦éœ€è¦ä½¿ç”¨Firecrawlè¿›è¡Œæ·±åº¦æŠ“å–
    
    è¿™ä¸ªèŠ‚ç‚¹ä¼šï¼š
    1. åˆ†æå½“å‰ç ”ç©¶ç»“æœçš„è´¨é‡
    2. è¯„ä¼°æ˜¯å¦éœ€è¦æ·±åº¦å†…å®¹å¢å¼º
    3. é€‰æ‹©ä¼˜å…ˆçš„URLè¿›è¡ŒFirecrawlæŠ“å–
    4. æ‰§è¡Œå†…å®¹å¢å¼ºï¼ˆå¦‚æœéœ€è¦ï¼‰
    5. å°†å¢å¼ºçš„å†…å®¹åˆå¹¶åˆ°ç ”ç©¶ç»“æœä¸­
    """
    
    try:
        # è·å–å½“å‰ç ”ç©¶ä¸Šä¸‹æ–‡
        plan = state.get("plan", [])
        current_pointer = state.get("current_task_pointer", 0)
        
        # ç¡®å®šç ”ç©¶ä¸»é¢˜
        if plan and current_pointer < len(plan):
            research_topic = plan[current_pointer]["description"]
        else:
            research_topic = state.get("user_query") or get_research_topic(state["messages"])
        
        # è·å–å½“å‰ç ”ç©¶å‘ç°
        current_findings = state.get("web_research_result", [])
        
        # è·å–grounding sourcesï¼ˆä»æœ€è¿‘çš„æœç´¢ç»“æœä¸­æå–ï¼‰
        grounding_sources = []
        sources_gathered = state.get("sources_gathered", [])
        for source in sources_gathered[-10:]:  # æœ€è¿‘çš„10ä¸ªæº
            if isinstance(source, dict):
                grounding_sources.append({
                    "title": source.get("title", ""),
                    "url": source.get("url", ""),
                    "snippet": source.get("snippet", "")
                })
        
        print(f"ğŸ¤” åˆ†æå†…å®¹å¢å¼ºéœ€æ±‚...")
        print(f"  ç ”ç©¶ä¸»é¢˜: {research_topic}")
        print(f"  å½“å‰å‘ç°æ•°é‡: {len(current_findings)}")
        print(f"  å¯ç”¨ä¿¡æ¯æº: {len(grounding_sources)}")
        
        # ä½¿ç”¨æ™ºèƒ½å†³ç­–å™¨è¿›è¡Œåˆ†æ
        decision = get_content_enhancement_decision_maker().analyze_enhancement_need(
            research_topic=research_topic,
            current_findings=current_findings,
            grounding_sources=grounding_sources,
            config=config
        )
        
        print(f"ğŸ“Š å¢å¼ºå†³ç­–ç»“æœ:")
        print(f"  éœ€è¦å¢å¼º: {decision.needs_enhancement}")
        print(f"  ç½®ä¿¡åº¦: {decision.confidence_score:.2f}")
        print(f"  å¢å¼ºç±»å‹: {decision.enhancement_type}")
        print(f"  ä¼˜å…ˆURLæ•°é‡: {len(decision.priority_urls)}")
        
        # ä¿å­˜å†³ç­–åˆ°çŠ¶æ€
        state_update = {
            "enhancement_decision": {
                "needs_enhancement": decision.needs_enhancement,
                "confidence_score": decision.confidence_score,
                "enhancement_type": decision.enhancement_type,
                "reasoning": decision.reasoning,
                "priority_urls": decision.priority_urls
            }
        }
        
        # å¦‚æœä¸éœ€è¦å¢å¼ºï¼Œç›´æ¥è¿”å›
        if not decision.needs_enhancement:
            print("âœ… å½“å‰å†…å®¹è´¨é‡å……è¶³ï¼Œæ— éœ€å¢å¼º")
            state_update["enhancement_status"] = "skipped"
            return state_update
        
        # å¦‚æœæ²¡æœ‰Firecrawl API Keyï¼Œè·³è¿‡å¢å¼º
        if not get_content_enhancement_decision_maker().firecrawl_app:
            print("âš ï¸ ç¼ºå°‘FIRECRAWL_API_KEYï¼Œè·³è¿‡å†…å®¹å¢å¼º")
            state_update["enhancement_status"] = "skipped_no_api"
            return state_update
        
        # æ‰§è¡Œå†…å®¹å¢å¼º
        print(f"ğŸ”¥ æ‰§è¡ŒFirecrawlå†…å®¹å¢å¼º...")
        enhanced_results = []
        
        # åŒæ­¥è°ƒç”¨ï¼ˆæš‚æ—¶ç®€åŒ–ï¼Œåç»­å¯æ”¹ä¸ºå¼‚æ­¥ï¼‰
        for url_info in decision.priority_urls:
            url = url_info.get("url")
            if not url:
                continue
            
            try:
                print(f"  æ­£åœ¨æŠ“å–: {url_info.get('title', 'Unknown')}")
                
                result = get_content_enhancement_decision_maker().firecrawl_app.scrape_url(url)
                
                if result and result.success:
                    markdown_content = result.markdown or ''
                    
                    enhanced_results.append({
                        "url": url,
                        "title": url_info.get("title", ""),
                        "original_priority": url_info.get("priority_score", 0),
                        "enhanced_content": markdown_content,
                        "content_length": len(markdown_content),
                        "source_type": "firecrawl_enhanced",
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    print(f"    âœ… æˆåŠŸ: {len(markdown_content)} å­—ç¬¦")
                else:
                    print(f"    âŒ å¤±è´¥: {result.error if hasattr(result, 'error') else 'æœªçŸ¥é”™è¯¯'}")
                    
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸: {str(e)}")
                continue
        
        if enhanced_results:
            # å°†å¢å¼ºå†…å®¹æ·»åŠ åˆ°ç ”ç©¶ç»“æœä¸­
            enhanced_contents = []
            for result in enhanced_results:
                # æ ¼å¼åŒ–å¢å¼ºå†…å®¹
                formatted_content = f"""

## æ·±åº¦å†…å®¹å¢å¼º - {result['title']}

æ¥æº: {result['url']}
å†…å®¹é•¿åº¦: {result['content_length']} å­—ç¬¦

{result['enhanced_content'][:3000]}{'...' if len(result['enhanced_content']) > 3000 else ''}

---
"""
                enhanced_contents.append(formatted_content)
            
            state_update.update({
                "enhanced_content_results": enhanced_results,
                "web_research_result": enhanced_contents,  # æ·»åŠ åˆ°ç ”ç©¶ç»“æœä¸­
                "enhancement_status": "completed",
                "enhanced_sources_count": len(enhanced_results)
            })
            
            print(f"âœ… å†…å®¹å¢å¼ºå®Œæˆ: {len(enhanced_results)} ä¸ªæº")
        else:
            print("âŒ å†…å®¹å¢å¼ºå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸæŠ“å–ä»»ä½•å†…å®¹")
            state_update["enhancement_status"] = "failed"
        
        return state_update
        
    except Exception as e:
        error_message = f"å†…å®¹å¢å¼ºåˆ†æèŠ‚ç‚¹å¼‚å¸¸: {str(e)}"
        print(f"âŒ {error_message}")
        return {
            "enhancement_status": "error",
            "enhancement_error": error_message
        }


def should_enhance_content(state: OverallState) -> str:
    """
    æ¡ä»¶è¾¹å‡½æ•° - å†³å®šæ˜¯å¦è¿›å…¥å†…å®¹å¢å¼ºæµç¨‹
    
    åŸºäºä»¥ä¸‹æ¡ä»¶åˆ¤æ–­:
    1. æ˜¯å¦é…ç½®äº†Firecrawl API Key
    2. å½“å‰ç ”ç©¶å¾ªç¯æ¬¡æ•°
    3. ç”¨æˆ·é…ç½®çš„å¢å¼ºåå¥½
    """
    
    # æ£€æŸ¥Firecrawlå¯ç”¨æ€§
    if not os.getenv("FIRECRAWL_API_KEY"):
        print("âš ï¸ è·³è¿‡å†…å®¹å¢å¼º: æœªé…ç½®FIRECRAWL_API_KEY")
        return "continue_without_enhancement"
    
    # æ£€æŸ¥ç ”ç©¶å¾ªç¯æ¬¡æ•°ï¼ˆé¿å…åœ¨æ—©æœŸå¾ªç¯ä¸­å¢å¼ºï¼‰
    research_loop_count = state.get("research_loop_count", 0)
    if research_loop_count < 1:  # è‡³å°‘è¿›è¡Œä¸€è½®ç ”ç©¶åå†è€ƒè™‘å¢å¼º
        print(f"âš ï¸ è·³è¿‡å†…å®¹å¢å¼º: ç ”ç©¶å¾ªç¯æ¬¡æ•°ä¸è¶³ ({research_loop_count})")
        return "continue_without_enhancement"
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»è¿›è¡Œè¿‡å¢å¼ºï¼ˆé¿å…é‡å¤å¢å¼ºï¼‰
    if state.get("enhancement_status") in ["completed", "skipped"]:
        print("âš ï¸ è·³è¿‡å†…å®¹å¢å¼º: å·²ç»å®Œæˆå¢å¼º")
        return "continue_without_enhancement"
    
    # æ£€æŸ¥å½“å‰å‘ç°æ•°é‡ï¼ˆè‡³å°‘è¦æœ‰ä¸€äº›åŸºç¡€å†…å®¹ï¼‰
    current_findings = state.get("web_research_result", [])
    if len(current_findings) < 1:
        print("âš ï¸ è·³è¿‡å†…å®¹å¢å¼º: ç¼ºå°‘åŸºç¡€ç ”ç©¶å†…å®¹")
        return "continue_without_enhancement"
    
    print("âœ… æ»¡è¶³å¢å¼ºæ¡ä»¶ï¼Œè¿›å…¥å†…å®¹å¢å¼ºåˆ†æ")
    return "analyze_enhancement_need"


def enhanced_reflection(state: OverallState, config: RunnableConfig) -> ReflectionState:
    """
    å¢å¼ºç‰ˆåæ€èŠ‚ç‚¹ - åœ¨åŸæœ‰reflectionåŸºç¡€ä¸Šè€ƒè™‘å†…å®¹å¢å¼ºçš„ç»“æœ
    """
    
    # å…ˆè°ƒç”¨åŸæœ‰çš„reflectioné€»è¾‘
    from agent.graph import reflection
    reflection_result = reflection(state, config)
    
    # å¦‚æœè¿›è¡Œäº†å†…å®¹å¢å¼ºï¼Œè°ƒæ•´reflectionçš„åˆ¤æ–­
    enhancement_status = state.get("enhancement_status")
    enhanced_sources_count = state.get("enhanced_sources_count", 0)
    
    if enhancement_status == "completed" and enhanced_sources_count > 0:
        print(f"ğŸ“ˆ å†…å®¹å¢å¼ºå®Œæˆï¼Œè°ƒæ•´åæ€åˆ¤æ–­")
        print(f"  å¢å¼ºäº† {enhanced_sources_count} ä¸ªä¿¡æ¯æº")
        
        # å¦‚æœæˆåŠŸå¢å¼ºäº†å†…å®¹ï¼Œæ›´å€¾å‘äºè®¤ä¸ºä¿¡æ¯å……è¶³
        # ä½†ä»ç„¶ä¿ç•™LLMçš„åˆ¤æ–­æƒé‡
        if not reflection_result["is_sufficient"]:
            # ç»™å¢å¼ºå†…å®¹ä¸€å®šçš„"åŠ åˆ†"
            enhancement_boost = min(enhanced_sources_count * 0.3, 0.8)
            print(f"  ç”±äºå†…å®¹å¢å¼ºï¼Œæå‡å……è¶³æ€§è¯„ä¼° (+{enhancement_boost:.1f})")
            
            # å¦‚æœå¢å¼ºæ•ˆæœå¾ˆå¥½ï¼Œå¯èƒ½å°†"ä¸å……è¶³"æ”¹ä¸º"å……è¶³"
            if enhancement_boost >= 0.6:
                print("  âœ… åŸºäºå†…å®¹å¢å¼ºç»“æœï¼Œåˆ¤å®šä¿¡æ¯å·²å……è¶³")
                reflection_result["is_sufficient"] = True
                reflection_result["knowledge_gap"] = "å†…å®¹å·²é€šè¿‡æ·±åº¦æŠ“å–å¾—åˆ°å……åˆ†è¡¥å……"
    
    elif enhancement_status == "skipped":
        print("ğŸ“ å†…å®¹å¢å¼ºè¢«è·³è¿‡ï¼Œä½¿ç”¨åŸå§‹åæ€ç»“æœ")
    
    elif enhancement_status == "failed":
        print("âš ï¸ å†…å®¹å¢å¼ºå¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ›´å¤šç ”ç©¶å¾ªç¯")
    
    return reflection_result


# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–å¢å¼ºå†³ç­–ä¿¡æ¯ç”¨äºæ—¥å¿—
def format_enhancement_decision_log(decision: EnhancementDecision) -> str:
    """æ ¼å¼åŒ–å¢å¼ºå†³ç­–ä¿¡æ¯ç”¨äºæ—¥å¿—è¾“å‡º"""
    
    log_lines = [
        f"ğŸ“Š å†…å®¹å¢å¼ºå†³ç­–æŠ¥å‘Š:",
        f"  å†³ç­–: {'éœ€è¦å¢å¼º' if decision.needs_enhancement else 'æ— éœ€å¢å¼º'}",
        f"  ç½®ä¿¡åº¦: {decision.confidence_score:.2f}",
        f"  å¢å¼ºç±»å‹: {decision.enhancement_type}",
        f"  ä¼˜å…ˆURLæ•°é‡: {len(decision.priority_urls)}"
    ]
    
    if decision.priority_urls:
        log_lines.append("  ä¼˜å…ˆURLs:")
        for i, url_info in enumerate(decision.priority_urls, 1):
            log_lines.append(f"    {i}. {url_info.get('title', 'N/A')} (è¯„åˆ†: {url_info.get('priority_score', 0):.2f})")
    
    log_lines.append(f"  æ¨ç†: {decision.reasoning[:200]}...")
    
    return "\n".join(log_lines) 